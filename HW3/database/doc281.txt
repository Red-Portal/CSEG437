  Recent advances in touch screen technology have increased the prevalence of touch screens and have prompted a wave of new touch screen-based devices. However, touch screens are still largely inaccessible to blind users, who must adopt error-prone compensatory strategies to use them or find accessible alternatives. This inaccessibility is due to interaction techniques that require the user to visually locate objects on the screen. To address this problem, we introduce Slide Rule, a set of audiobased multi-touch interaction techniques that enable blind users to
access touch screen applications. We describe the design of Slide Rule, our interaction techniques, and a user study in which 10 blind people used Slide Rule and a button-based Pocket PC screen reader. Results show that Slide Rule was significantly faster than the button-based system, and was preferred by 7 of 10 users. However, users made more errors when using Slide Rule than when using the more familiar button-based system.

  Although touch screens have existed for decades, new advances in touch screen interfaces, as seen in devices such as Apple¡¯'s iPhone and Microsoft Surface, have renewed interest in touch interfaces. Touch screens are often used to provide information and services to users in places such as museums, airports, and supermarkets. Increasingly, touch screens are also a common interface element of mobile devices such as Tablet PCs, PDAs, and smartphones. Touch screen interfaces offer users several advantages over interfaces with physical buttons. One advantage is flexibility of presentation and control. A touch screen device can display different interfaces on the same surface, such as a scrollable list, a QWERTY keyboard, or a telephone keypad. Another advantage of touch screen interfaces is discoverability. Rather than requiring users to remember input commands, touch screens allow users to directly manipulate items on the screen.
New multi-touch user interfaces support additional interaction techniques beyond pointing and tapping, allowing users to interact using single- and multi-finger gestures such as flicking, rotating, and pinching. Unfortunately, touch screens can present significant accessibility barriers to blind users. Most touch screens provide no audio or tactile feedback, making it difficult or impossible to locate items on the screen. Because of these difficulties, blind users may need to be shown the locations of on-screen objects by a sighted person, may need to use an alternative accessible interface (if available), or may be completely unable to use a device. Although some assistive technologies can improve touch screen accessibility, these typically require additional hardware buttons (e.g., [18]), or provide only limited use of the touch screen (e.g., Mobile Speak Pocket1). Thus, most current touch screen interfaces remain inaccessible to blind users.
In response to these limitations, we developed Slide Rule, a set of accessible multi-touch interaction techniques for touch screen interfaces. Slide Rule provides a completely non-visual interface that repurposes a touch screen as a ¡°"talking¡±" touch-sensitive surface. Slide Rule uses a set of four basic gesture interactions: Slide Rule provides access to custom phone book, email, and media player applications that we developed for this evaluation. Slide Rule requires a standard multi-touch screen and audio output, but no additional hardware. In this paper, we describe the design, implementation, and evaluation of Slide Rule. We present our user-centered design process that included formative interviews with 8 blind mobile
device users, followed by iterative prototyping with 3 blind users. We describe a study in which 10 blind people used Slide Rule and a comparable button-based system running the Mobile Speak Pocket screen reader. Our results show that users were faster with Slide Rule and that 7 of 10 participants preferred Slide Rule. However, participants committed more errors with Slide Rule, resulting in a speed-accuracy tradeoff. Finally, we discuss the design implications of this study and possibilities for future work, including the generalization of our techniques to other touch screen-based devices and surface computing platforms.
